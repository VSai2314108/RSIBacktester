{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h5/3j0f0wrs0b7btzg_w3kksr9m0000gn/T/ipykernel_28568/2371212410.py:2: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79bc0aa8b7f54bfdb240883817fcb901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing branches:   0%|          | 0/1006 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm.autonotebook import tqdm\n",
    "def load_data(ticker):\n",
    "    file_path = f'./indicator_data/{ticker}.csv'\n",
    "    df = pd.read_csv(file_path, index_col='date', parse_dates=True)\n",
    "    return df\n",
    "\n",
    "def evaluate_condition(df, indicator, direction, value, days):\n",
    "    indicator_values = df[indicator]\n",
    "    \n",
    "    if direction == '>':\n",
    "        condition = indicator_values > value\n",
    "    else:\n",
    "        condition = indicator_values < value\n",
    "    \n",
    "    # Change the rolling operation\n",
    "    return condition.rolling(window=days).min() == 1\n",
    "\n",
    "def evaluate_branch(branch):\n",
    "    parts = branch.split('-')\n",
    "    indicator, period, indicator_ticker, direction, threshold, days, trading_ticker = parts\n",
    "    \n",
    "    indicator_df = load_data(indicator_ticker)\n",
    "    trading_df = load_data(trading_ticker)\n",
    "    \n",
    "    common_dates = indicator_df.index.intersection(trading_df.index)\n",
    "    indicator_df = indicator_df.loc[common_dates]\n",
    "    trading_df = trading_df.loc[common_dates]\n",
    "    \n",
    "    condition_met = evaluate_condition(indicator_df, f\"{indicator}_{period}\", direction, float(threshold), int(days))\n",
    "    \n",
    "    result = pd.DataFrame(index=trading_df.index)\n",
    "    result['condition_met'] = condition_met.astype(int)\n",
    "    \n",
    "    # Shift condition_met forward by one day and calculate trade returns\n",
    "    result['shifted_condition'] = result['condition_met'].shift(1)\n",
    "    result['trade_returns_day'] = (result['shifted_condition'] * trading_df['close'].pct_change()) + 1\n",
    "    \n",
    "    # return result[['condition_met', 'trade_returns_day']].to_dict(orient='index')\n",
    "    return result[['trade_returns_day']]\n",
    "\n",
    "\n",
    "def compute_monthly_returns(branch, df):\n",
    "    \n",
    "    df['year'] = df.index.year\n",
    "    df['month'] = df.index.month\n",
    "    monthly_returns = df.groupby(['year', 'month'])['trade_returns_day'].prod()\n",
    "    \n",
    "    # set the branch as the index and each month-year as a column\n",
    "    monthly_returns = monthly_returns.reset_index()\n",
    "    monthly_returns['month-year'] = monthly_returns['year'].astype(str) + '-' + monthly_returns['month'].astype(str).str.zfill(2)\n",
    "    monthly_returns['branch'] = branch\n",
    "    monthly_returns = monthly_returns.pivot(index='month-year', columns='branch', values='trade_returns_day')\n",
    "    return monthly_returns\n",
    "\n",
    "def batch_processor(branches):\n",
    "    monthly_returns_df = pd.DataFrame()\n",
    "    for branch in branches:\n",
    "        result = evaluate_branch(branch)\n",
    "        monthly_returns = compute_monthly_returns(branch, result)\n",
    "        monthly_returns_df = pd.concat([monthly_returns_df, monthly_returns], axis=1)\n",
    "    return monthly_returns_df\n",
    "\n",
    "branches = []\n",
    "with open('branches.txt', 'r') as file:\n",
    "    branches = [line.strip() for line in file]\n",
    "    \n",
    "batch_size = 100\n",
    "for i in tqdm(range(0, len(branches), batch_size), desc=\"Processing branches\"):\n",
    "    batch = branches[i:i+batch_size]\n",
    "    monthly_returns_df = batch_processor(batch)\n",
    "    monthly_returns_df.to_parquet(f'./monthly_returns/monthly_returns_{i//batch_size}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "branch\n",
      "rsi-3-SPXL-<-78-1-SPXL    7.233796\n",
      "rsi-3-SPXL-<-79-1-SPXL    7.233796\n",
      "rsi-3-SPXL-<-80-1-SPXL    7.233796\n",
      "rsi-3-SPXL-<-81-1-SPXL    7.233796\n",
      "rsi-3-SPXL-<-82-1-SPXL    7.233796\n",
      "                            ...   \n",
      "rsi-3-SPXL-<-24-1-SPXL    4.340278\n",
      "rsi-3-SPXL-<-25-1-SPXL    4.340278\n",
      "rsi-3-SPXL-<-12-1-SPXL    4.340278\n",
      "rsi-3-SPXL-<-13-1-SPXL    4.340278\n",
      "rsi-3-SPXL-<-14-1-SPXL    4.340278\n",
      "Name: 2010-12-01 00:00:00, Length: 100, dtype: float64\n",
      "['rsi-3-SPXL-<-78-1-SPXL', 'rsi-3-SPXL-<-79-1-SPXL', 'rsi-3-SPXL-<-80-1-SPXL', 'rsi-3-SPXL-<-81-1-SPXL', 'rsi-3-SPXL-<-82-1-SPXL', 'rsi-3-SPXL-<-83-1-SPXL', 'rsi-3-SPXL-<-84-1-SPXL', 'rsi-2-SPXL-<-16-1-SPXL', 'rsi-2-SPXL-<-17-1-SPXL', 'rsi-2-SPXL-<-18-1-SPXL', 'rsi-2-SPXL-<-19-1-SPXL', 'rsi-2-SPXL-<-20-1-SPXL', 'rsi-2-SPXL-<-21-1-SPXL', 'rsi-2-SPXL-<-22-1-SPXL', 'rsi-2-SPXL-<-23-1-SPXL', 'rsi-2-SPXL-<-24-1-SPXL', 'rsi-2-SPXL-<-25-1-SPXL', 'rsi-2-SPXL-<-26-1-SPXL', 'rsi-2-SPXL-<-27-1-SPXL', 'rsi-2-SPXL-<-28-1-SPXL', 'rsi-2-SPXL-<-29-1-SPXL', 'rsi-3-SPXL-<-85-1-SPXL', 'rsi-3-SPXL-<-86-1-SPXL', 'rsi-3-SPXL-<-87-1-SPXL', 'rsi-3-SPXL-<-88-1-SPXL', 'rsi-3-SPXL-<-89-1-SPXL', 'rsi-3-SPXL-<-90-1-SPXL', 'rsi-3-SPXL-<-91-1-SPXL', 'rsi-2-SPXL-<-9-1-SPXL', 'rsi-2-SPXL-<-10-1-SPXL', 'rsi-2-SPXL-<-11-1-SPXL', 'rsi-2-SPXL-<-12-1-SPXL', 'rsi-2-SPXL-<-13-1-SPXL', 'rsi-2-SPXL-<-14-1-SPXL', 'rsi-2-SPXL-<-15-1-SPXL', 'rsi-3-SPXL-<-75-1-SPXL', 'rsi-3-SPXL-<-76-1-SPXL', 'rsi-3-SPXL-<-77-1-SPXL', 'rsi-2-SPXL-<-1-1-SPXL', 'rsi-2-SPXL-<-2-1-SPXL', 'rsi-2-SPXL-<-3-1-SPXL', 'rsi-2-SPXL-<-4-1-SPXL', 'rsi-2-SPXL-<-5-1-SPXL', 'rsi-2-SPXL-<-6-1-SPXL', 'rsi-2-SPXL-<-7-1-SPXL', 'rsi-2-SPXL-<-8-1-SPXL', 'rsi-2-SPXL-<-82-1-SPXL', 'rsi-2-SPXL-<-83-1-SPXL', 'rsi-2-SPXL-<-84-1-SPXL', 'rsi-2-SPXL-<-85-1-SPXL', 'rsi-2-SPXL-<-86-1-SPXL', 'rsi-2-SPXL-<-87-1-SPXL', 'rsi-2-SPXL-<-88-1-SPXL', 'rsi-3-SPXL-<-92-1-SPXL', 'rsi-3-SPXL-<-93-1-SPXL', 'rsi-3-SPXL-<-94-1-SPXL', 'rsi-3-SPXL-<-95-1-SPXL', 'rsi-3-SPXL-<-96-1-SPXL', 'rsi-3-SPXL-<-97-1-SPXL', 'rsi-3-SPXL-<-98-1-SPXL', 'rsi-3-SPXL-<-99-1-SPXL', 'rsi-2-SPXL-<-75-1-SPXL', 'rsi-2-SPXL-<-76-1-SPXL', 'rsi-2-SPXL-<-77-1-SPXL', 'rsi-2-SPXL-<-78-1-SPXL', 'rsi-2-SPXL-<-79-1-SPXL', 'rsi-2-SPXL-<-80-1-SPXL', 'rsi-2-SPXL-<-81-1-SPXL', 'rsi-2-SPXL-<-89-1-SPXL', 'rsi-2-SPXL-<-90-1-SPXL', 'rsi-2-SPXL-<-91-1-SPXL', 'rsi-2-SPXL-<-92-1-SPXL', 'rsi-2-SPXL-<-93-1-SPXL', 'rsi-2-SPXL-<-94-1-SPXL', 'rsi-2-SPXL-<-95-1-SPXL', 'rsi-2-SPXL-<-96-1-SPXL', 'rsi-2-SPXL-<-97-1-SPXL', 'rsi-2-SPXL-<-98-1-SPXL', 'rsi-2-SPXL-<-99-1-SPXL', 'rsi-3-SPXL-<-26-1-SPXL', 'rsi-3-SPXL-<-27-1-SPXL', 'rsi-3-SPXL-<-28-1-SPXL', 'rsi-3-SPXL-<-29-1-SPXL', 'rsi-3-SPXL-<-5-1-SPXL', 'rsi-3-SPXL-<-6-1-SPXL', 'rsi-3-SPXL-<-7-1-SPXL', 'rsi-3-SPXL-<-8-1-SPXL', 'rsi-3-SPXL-<-9-1-SPXL', 'rsi-3-SPXL-<-10-1-SPXL', 'rsi-3-SPXL-<-11-1-SPXL', 'rsi-3-SPXL-<-19-1-SPXL', 'rsi-3-SPXL-<-20-1-SPXL', 'rsi-3-SPXL-<-21-1-SPXL', 'rsi-3-SPXL-<-22-1-SPXL', 'rsi-3-SPXL-<-23-1-SPXL', 'rsi-3-SPXL-<-24-1-SPXL', 'rsi-3-SPXL-<-25-1-SPXL', 'rsi-3-SPXL-<-12-1-SPXL', 'rsi-3-SPXL-<-13-1-SPXL', 'rsi-3-SPXL-<-14-1-SPXL']\n",
      "                        back_period_returns  forward_period_returns\n",
      "branch                                                             \n",
      "rsi-3-SPXL-<-78-1-SPXL             7.233796                1.200000\n",
      "rsi-3-SPXL-<-79-1-SPXL             7.233796                1.200000\n",
      "rsi-3-SPXL-<-80-1-SPXL             7.233796                1.200000\n",
      "rsi-3-SPXL-<-81-1-SPXL             7.233796                1.200000\n",
      "rsi-3-SPXL-<-82-1-SPXL             7.233796                1.200000\n",
      "...                                     ...                     ...\n",
      "rsi-3-SPXL-<-13-1-SPXL             4.340278                1.200000\n",
      "rsi-3-SPXL-<-14-1-SPXL             4.340278                1.200000\n",
      "avg                              562.615741               30.800000\n",
      "portion_of_year                    0.830137                0.161644\n",
      "cagr                            1327.517281              362.462612\n",
      "\n",
      "[103 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# extract results\n",
    "import os\n",
    "import pandas as pd\n",
    "def gather_monthly_returns(directory):\n",
    "    monthly_returns_df = pd.DataFrame()\n",
    "    files = [f for f in os.listdir(directory) if f.endswith('.parquet')]\n",
    "    for file in files:\n",
    "        monthly_returns_df = pd.concat([monthly_returns_df, pd.read_parquet(os.path.join(directory, file))], axis=1)\n",
    "    return monthly_returns_df\n",
    "\n",
    "def one_back_one_forward(monthly_returns_df, back_start, back_end, forward_start, forward_end, top_n):\n",
    "    # expect string in yyyy-mm format and convert if it is not already datetime\n",
    "    if isinstance(back_start, str)  :\n",
    "        back_start = pd.to_datetime(back_start)\n",
    "    if isinstance(back_end, str):\n",
    "        back_end = pd.to_datetime(back_end)\n",
    "    if isinstance(forward_start, str):\n",
    "        forward_start = pd.to_datetime(forward_start)\n",
    "    if isinstance(forward_end, str):\n",
    "        forward_end = pd.to_datetime(forward_end)\n",
    "    \n",
    "    back_returns = monthly_returns_df.loc[back_start:back_end]\n",
    "    forward_returns = monthly_returns_df.loc[forward_start:forward_end]\n",
    "    \n",
    "    # do the cumprod of each branch in the back period and then choose the top n branches\n",
    "    back_period_returns = back_returns.cumprod()\n",
    "    top_n_branches = back_period_returns.iloc[-1].nlargest(top_n)\n",
    "    print(top_n_branches)\n",
    "    \n",
    "    branches_to_check = top_n_branches.index.tolist()\n",
    "    print(branches_to_check)\n",
    "    \n",
    "    forward_period_returns = forward_returns.cumprod()\n",
    "    forward_period_returns = forward_period_returns.iloc[-1].loc[branches_to_check]\n",
    "    combined_returns = forward_period_returns.mean()\n",
    "    \n",
    "    # combine the back period returns and the forward period returns with the branch as index \n",
    "    dataset = pd.concat([top_n_branches, forward_period_returns], axis=1)\n",
    "    dataset.columns = ['back_period_returns', 'forward_period_returns']\n",
    "    # add a row for the averages\n",
    "    dataset.loc['avg'] = ((dataset.mean()-1) * 100)\n",
    "    dataset.loc['portion_of_year'] = [(back_end - back_start).days / 365, (forward_end - forward_start).days / 365]\n",
    "    dataset.loc['cagr'] = ((dataset.mean() - 1)*100) / dataset.loc['portion_of_year']\n",
    "    print(dataset)\n",
    "    \n",
    "    # get those brnaches for the forward period and multiply the returns\n",
    "    # average the returns for the forward period\n",
    "   \n",
    "    \n",
    "    # multiply the top n branches returns with the forward period returns\n",
    "    # combined_returns = top_n_branches.mul(forward_returns)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "monthly_returns_df = gather_monthly_returns('./monthly_returns')\n",
    "# convert the index to datetime\n",
    "monthly_returns_df.index = pd.to_datetime(monthly_returns_df.index)\n",
    "# print(monthly_returns_df.head(5))\n",
    "\n",
    "back_start = \"2010-02\"\n",
    "back_end = \"2010-12\"\n",
    "forward_start = \"2011-01\"\n",
    "forward_end = \"2011-03\"\n",
    "top_n = 100\n",
    "\n",
    "dataset = one_back_one_forward(monthly_returns_df, back_start, back_end, forward_start, forward_end, top_n)\n",
    "\n",
    "# save the dataset to a csv file\n",
    "dataset.to_csv('./dataset.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
